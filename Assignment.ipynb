{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1question creating a MDP \n",
    "def createMDP ( probSuccess , gridSize ) :\n",
    "    #Number of actions\n",
    "    k  = 4 ;  \n",
    "    #set of actions L,R,U,D\n",
    "    actionLiist = [ 0, 1, 2, 3]  ; \n",
    "    # defining probability tranisition matrix\n",
    "    probTransitionMatrix = np.zeros((gridSize , gridSize ,gridSize , gridSize , k )) ;\n",
    "    n = gridSize ;\n",
    "    p = probSuccess ;\n",
    "    # assuming successful action takes to right state with probability p\n",
    "    # and unsuccessful action remains in the same state with probabiliy (1-p)\n",
    "    for i in range(0,n) :\n",
    "        for j in range(0,n) :\n",
    "            for k in range(0,4) :\n",
    "                probTransitionMatrix[i][j][i][j][k] = 1 - p ;\n",
    "                if( k == 0 ) :\n",
    "                    if(j > 0 ) :\n",
    "                        probTransitionMatrix[i][j][i][j-1][k] = p ;\n",
    "                    else :\n",
    "                        probTransitionMatrix[i][j][i][j][k] = 1 ;\n",
    "                if ( k == 1 ) :\n",
    "                    if(j < (n-1) ) :\n",
    "                        probTransitionMatrix[i][j][i][j+1][k] = p ;\n",
    "                    else :\n",
    "                        probTransitionMatrix[i][j][i][j][k] = 1 ;\n",
    "                if ( k == 2 ) :\n",
    "                    if(i > 0 ) :\n",
    "                        probTransitionMatrix[i][j][i-1][j][k] = p ;\n",
    "                    else :\n",
    "                        probTransitionMatrix[i][j][i][j][k] = 1 ;\n",
    "                if ( k == 3 ) :\n",
    "                    if(i < (n-1) ) :\n",
    "                        probTransitionMatrix[i][j][i+1][j][k] = p ;\n",
    "                    else :\n",
    "                        probTransitionMatrix[i][j][i][j][k] = 1 ;\n",
    "    #initlaising reward matrix ...\n",
    "    rewardMatrix = np.zeros((n,n)) ;\n",
    "    rewardMatrix[n-1][n-1] = 100 ;\n",
    "    rewardMatrix[0][0] = 10 \n",
    "    return  (probTransitionMatrix , rewardMatrix) ; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random SDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## questionNo.2\n",
    "## random SDP \n",
    "def randomSDP (MDP) :\n",
    "    #size of MDP \n",
    "    n = MDP[0].shape[0] ; \n",
    "    policy = np.zeros((n,n)) ;\n",
    "    action = [0, 1, 2, 3] ;\n",
    "    for i in range(0,n) :\n",
    "        for j in range (0,n) :\n",
    "            policy[i][j] = int(random.choice(action)) ;\n",
    "    return policy ; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gauss Elimination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## questionNo.3 \n",
    "## Gauss Elimination \n",
    "def gaussElimination(a, b):\n",
    "    a = copy.deepcopy(a)\n",
    "    b = copy.deepcopy(b)\n",
    "    n = len(a)\n",
    "    p = len(b[0])\n",
    "    det = 1\n",
    "    for i in range(n - 1):\n",
    "        k = i\n",
    "        for j in range(i + 1, n):\n",
    "            if abs(a[j][i]) > abs(a[k][i]):\n",
    "                k = j\n",
    "        if k != i:\n",
    "            a[i], a[k] = a[k], a[i]\n",
    "            b[i], b[k] = b[k], b[i]\n",
    "            det = -det\n",
    " \n",
    "        for j in range(i + 1, n):\n",
    "            t = a[j][i]/a[i][i]\n",
    "            for k in range(i + 1, n):\n",
    "                a[j][k] -= t*a[i][k]\n",
    "            for k in range(p):\n",
    "                b[j][k] -= t*b[i][k]\n",
    " \n",
    "    for i in range(n - 1, -1, -1):\n",
    "        for j in range(i + 1, n):\n",
    "            t = a[i][j]\n",
    "            for k in range(p):\n",
    "                b[i][k] -= t*b[j][k]\n",
    "        t = 1/a[i][i]\n",
    "        det *= a[i][i]\n",
    "        for j in range(p):\n",
    "            b[i][j] *= t\n",
    "    return (det, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hash( i , j , n) :\n",
    "    return int(i*n + j) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value via inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculatining Vu \n",
    "## question No. 4 \n",
    "def valueviainverse ( prob , rew , gamma) :  \n",
    "    MDP = (prob , rew) ;\n",
    "    policy = randomSDP(MDP) ;\n",
    "    n = MDP[0].shape[0] ;\n",
    "    probTrans = MDP[0] ;\n",
    "    P =  np.zeros((n*n,n*n)) ;\n",
    "    R =  np.zeros((n*n))\n",
    "    for i in range(0,n) :\n",
    "        for j in range(0,n) :\n",
    "            R[Hash(i,j,n)] = rew[i][j] ;\n",
    "            k = int(policy[i][j]) ;\n",
    "            P[Hash(i,j,n)][Hash(i,j,n)] = probTrans[i][j][i][j][k]; \n",
    "            if( k == 0 ) :\n",
    "                if(j > 0 ) :\n",
    "                    P[Hash(i,j,n)][Hash(i,j-1,n)] = probTrans[i][j][i][j-1][k];\n",
    "            if ( k == 1 ) :\n",
    "                if(j < (n-1) ) :\n",
    "                    P[Hash(i,j,n)][Hash(i,j+1,n)] = probTrans[i][j][i][j+1][k] ; \n",
    "            if ( k == 2 ) :\n",
    "                if(i > 0 ) :\n",
    "                    P[Hash(i,j,n)][Hash(i-1,j,n)] = probTrans[i][j][i-1][j][k];\n",
    "            if ( k == 3 ) :\n",
    "                if(i < (n-1) ) :\n",
    "                    P[Hash(i,j,n)][Hash(i+1,j,n)] = probTrans[i][j][i+1][j][k];\n",
    "    P = gamma*P ;\n",
    "    I = np.identity(n*n) ;\n",
    "    Inv = np.subtract(I , P) ;\n",
    "    Inv  = np.linalg.inv(Inv) ;\n",
    "    V = Inv.dot(R) ;\n",
    "    Vu = np.zeros((n,n)) ;\n",
    "    for i in range(0,n*n) :\n",
    "        y = i % n ;\n",
    "        x = (i - y) // n ;\n",
    "        Vu[x][y] = V[i] ;         \n",
    "    return Vu ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bellman operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question No 5 \n",
    "## bellman operator \n",
    "def BellmanOperator(V , P , R , Pu , gamma) :\n",
    "    Pu = gamma*Pu ;\n",
    "    V = R + Pu.dot(V) ;\n",
    "    return V ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question No 6 \n",
    "def valueEvaluation(prob , rew , gamma) :\n",
    "    MDP = (prob , rew) ;\n",
    "    policy = randomSDP(MDP) ;\n",
    "    n = MDP[0].shape[0] ;\n",
    "    probTrans = MDP[0] ;\n",
    "    P =  np.zeros((n*n,n*n)) ;\n",
    "    R =  np.zeros((n*n))\n",
    "    for i in range(0,n) :\n",
    "        for j in range(0,n) :\n",
    "            R[Hash(i,j,n)] = rew[i][j] ;\n",
    "            k = int(policy[i][j]) ;\n",
    "            P[Hash(i,j,n)][Hash(i,j,n)] = probTrans[i][j][i][j][k]; \n",
    "            if( k == 0 ) :\n",
    "                if(j > 0 ) :\n",
    "                    P[Hash(i,j,n)][Hash(i,j-1,n)] = probTrans[i][j][i][j-1][k];\n",
    "            if ( k == 1 ) :\n",
    "                if(j < (n-1) ) :\n",
    "                    P[Hash(i,j,n)][Hash(i,j+1,n)] = probTrans[i][j][i][j+1][k] ; \n",
    "            if ( k == 2 ) :\n",
    "                if(i > 0 ) :\n",
    "                    P[Hash(i,j,n)][Hash(i-1,j,n)] = probTrans[i][j][i-1][j][k];\n",
    "            if ( k == 3 ) :\n",
    "                if(i < (n-1) ) :\n",
    "                    P[Hash(i,j,n)][Hash(i+1,j,n)] = probTrans[i][j][i+1][j][k];\n",
    "    \n",
    "    V = np.zeros((n*n)) ;       \n",
    "    Vu = np.zeros((n,n)) \n",
    "    \n",
    "    for i in range(1000) :\n",
    "        V = BellmanOperator(V,P,R,P,gamma) ;    \n",
    "    for i in range(0,n*n) :\n",
    "        y = i % n ;\n",
    "        x = (i - y) // n ;\n",
    "        Vu[x][y] = V[i] ;         \n",
    "        \n",
    "    return Vu ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question No.7 \n",
    "#RandomWalk\n",
    "def RandomWalk(L, policy , P , R) : \n",
    "    \n",
    "    j,k = 1,1 ;\n",
    "    \n",
    "    n = R.shape[0] ;\n",
    "    \n",
    "    for i in range(L) :\n",
    "        k1 = int(policy[j][k]) ;\n",
    "        l = [] ;\n",
    "        l1 = [] ;\n",
    "        for i1 in range(n) :\n",
    "            for j1 in range(n) :\n",
    "                l.append(P[k][j][i1][j1][k1]) ;\n",
    "                l1.append(i1*n+j1) ;\n",
    "        x1 = np.random.choice(l1,p=l) ;\n",
    "        j1 = x1 % n ;\n",
    "        k1 = (x1 - j1) // n ;\n",
    "        print (\" ( ({}, {}) , {} , ({}, {}) )\".format(j,k,R[j][k],j1,k1)) ;\n",
    "        j = j1 ;\n",
    "        k = k1 ;\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the value matrix using a random policy generated by SDP and also via inverse method\n",
      "[[ 100.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0. 1000.]]\n",
      "Printing the value matrix using a random policy generated by SDP and also via iteration method\n",
      "[[ 100.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0. 1000.]]\n",
      "Random Walk\n",
      " ( (1, 1) , 0.0 , (1, 0) )\n",
      " ( (1, 0) , 0.0 , (1, 0) )\n",
      " ( (1, 0) , 0.0 , (1, 0) )\n",
      " ( (1, 0) , 0.0 , (1, 0) )\n",
      " ( (1, 0) , 0.0 , (1, 0) )\n",
      " ( (1, 0) , 0.0 , (1, 0) )\n",
      " ( (1, 0) , 0.0 , (0, 0) )\n",
      " ( (0, 0) , 10.0 , (0, 0) )\n",
      " ( (0, 0) , 10.0 , (0, 0) )\n",
      " ( (0, 0) , 10.0 , (0, 0) )\n",
      " ( (0, 0) , 10.0 , (0, 0) )\n",
      " ( (0, 0) , 10.0 , (0, 0) )\n",
      " ( (0, 0) , 10.0 , (0, 0) )\n",
      " ( (0, 0) , 10.0 , (0, 0) )\n",
      " ( (0, 0) , 10.0 , (0, 0) )\n",
      " ( (0, 0) , 10.0 , (0, 0) )\n",
      " ( (0, 0) , 10.0 , (0, 0) )\n",
      " ( (0, 0) , 10.0 , (0, 0) )\n",
      " ( (0, 0) , 10.0 , (0, 0) )\n",
      " ( (0, 0) , 10.0 , (0, 0) )\n"
     ]
    }
   ],
   "source": [
    "#testing \n",
    "MDP = createMDP(0.5, 3) ;\n",
    "prob = MDP[0] ;\n",
    "rew = MDP[1] ;\n",
    "pol = randomSDP(MDP) ;\n",
    "print(\"Printing the value matrix using a random policy generated by SDP and also via inverse method\")\n",
    "print(valueviainverse(prob,rew,0.9)) ;\n",
    "print(\"Printing the value matrix using a random policy generated by SDP and also via iteration method\")\n",
    "print(valueEvaluation(prob,rew,0.9)) ;\n",
    "print(\"Random Walk\")\n",
    "RandomWalk(20,pol,prob,rew)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
